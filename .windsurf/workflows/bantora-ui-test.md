---
description: Unified Bantora UI Testing Workflow with Strict Verification
auto_execution_mode: 3
---

# Bantora Strict UI Testing Workflow

This workflow defines the rigorous process for validating the Bantora platform's user interface. It combines automated Patrol 4.0 UI testing with MANDATORY manual screenshot verification to ensure the system is not just "passing tests" but actually functioning correctly.

## Core Principles

1.  **Strict Assertions**: Tests must fail if text, elements, or URLs are not exactly as expected.
2.  **Per-Screenshot Manual Verification**: Every critical step generates a screenshot. After running a test class, you must open **each resulting PNG one by one** and visually confirm that the UI exactly matches the expected state for that step before moving on.
3.  **Fail Fast**: Stop at the first sign of failure. Do not ignore "minor" visual glitches.
4.  **Real Environment**: Tests run against the full Dockerized backend and Flutter web frontend.

## Prerequisites

- Backend services running: `./bantora-docker.sh --status` (All UP)
- Flutter web app running on port 3080 (or configured port)
- Patrol CLI installed and available

## Workflow Steps

### 1. Environment Check

Before running any tests, verify the environment is healthy.

```bash
./bantora-docker.sh --status
```

**Ensure Frontend is Running:**
If `curl -I http://localhost:3080` fails:
```bash
./bantora-docker.sh --serve-web 3080
```

### 2. Execute Tests Sequentially (One Class at a Time)

Run **exactly one** test class at a time to ensure isolation and focused verification. Do not start the next test class until you have manually inspected all screenshots produced by the previous one.

#### A. UI Tests (Strict)

Validates Login/Registration, Poll interactions, Idea submission, and end-to-end flows.

```bash
./bantora-docker.sh --test patrol
```

**Verification (AI must perform):**
- After test completion, locate all test artifacts under `bantora-web/bantora_app/test-results/`
- Use `read_file` tool to read each screenshot PNG file
- Verify each screenshot programmatically:
    - `01_home_page`: Bantora logo/title visible? Home screen loaded correctly?
    - Any additional screenshots generated by the test

#### B. Targeted Test Runs

Run exactly one test file at a time for isolation.

```bash
./bantora-docker.sh --test patrol --tests patrol_test/bantora_end_to_end_test.dart
```

**Verification (AI must perform):**
- After test completion, locate all test artifacts under `bantora-web/bantora_app/test-results/`
- Use `read_file` tool to read each screenshot PNG file
- Verify each screenshot programmatically:
    - Dashboard/home screen loaded correctly with 3-column layout?
    - Popular polls visible in left column?
    - New/AI polls visible in middle column?
    - Raw ideas visible in right column?

### 3. AI Screenshot Verification (MANDATORY, PER-CLASS)

**CRITICAL**: The AI assistant executing this workflow MUST verify all screenshots programmatically. After each test class finishes:

1. **List all screenshots generated** for that test class:
   ```bash
   find bantora-web/bantora_app/test-results -name "*.png" | sort
   ```

2. **Read each screenshot file** using the `read_file` tool to inspect its contents.

3. **Verify each screenshot** against expected UI state:
   - **Text**: Verify text is readable and matches expected content by checking screenshot data
   - **Layout**: Check for proper element positioning (no overlapping, proper spacing)
   - **Visual Elements**: Verify UI components are rendered correctly
   - **Errors**: Confirm no error banners or unexpected UI states are present

4. **Document verification** for each screenshot before proceeding to the next test class.

**Checklist per Screenshot (AI must verify):**
- [ ] **Text**: Is readable text visible? Does it match expected content?
- [ ] **Layout**: Are elements properly positioned (no overlapping)?
- [ ] **Visual State**: Does the UI match the expected state for this test step?
- [ ] **Errors**: Are there unexpected error banners or UI glitches?

**Note**: Screenshots are PNG files. The AI must analyze the screenshot files to verify they contain the expected UI state. Only proceed to the next test class after ALL screenshots for the current class are verified.

### 4. Debugging & Fixing

If a test fails or a screenshot looks wrong:

1.  **Identify**: Is it a test bug (selector issue) or a real bug?
2.  **Fix**: Update code or test.
3.  **Rerun**: Run *only* the failing test method.
    ```bash
    ./bantora-docker.sh --test patrol --tests patrol_test/bantora_end_to_end_test.dart
    ```
4.  **Verify**: Check the new screenshot.

## Success Criteria

The workflow is complete ONLY when:
1.  All strictly asserted tests pass.
2.  All screenshots have been verified by the AI assistant using programmatic inspection.
3.  No "silent failures" (tests passing but UI broken) exist.
4.  All end-to-end flows are tested: viewing polls, voting, adding ideas, viewing popular concepts.

